#  Automated Machine Learning Pipeline â€” *Industry-Grade End-to-End Implementation*

![Python](https://img.shields.io/badge/Python-3.10%2B-blue.svg)
![MLflow](https://img.shields.io/badge/MLflow-Tracking-orange)
![DVC](https://img.shields.io/badge/DVC-Data%20Versioning-purple)
![DagsHub](https://img.shields.io/badge/DagsHub-Integrated%20Tracking-green)
![Docker](https://img.shields.io/badge/Docker-Containerized-lightblue)
![Status](https://img.shields.io/badge/Status-Active-brightgreen)

---

## ğŸ§  Project Overview

This repository implements a **complete, end-to-end Machine Learning pipeline**, following **real-world MLOps best practices**.  
Built using **Python**, this project leverages **DVC**, **MLflow**, and **DagsHub** to enable experiment tracking, data versioning, and full pipeline reproducibility.

The system trains multiple ML models on a dataset, evaluates them, and automatically identifies and stores the **best-performing model** â€” with all results logged for visualization and comparison.

---

## âš™ï¸ Key Features

âœ… **End-to-End ML Pipeline** â€” from data ingestion to model deployment readiness  
âœ… **MLflow Integration** â€” tracks all metrics, parameters, and artifacts  
âœ… **DVC Integration** â€” ensures dataset and model reproducibility  
âœ… **DagsHub Connectivity** â€” cloud-based tracking and visualization  
âœ… **Multi-Model Evaluation** â€” trains and compares multiple ML models automatically  
âœ… **Docker Support** â€” complete containerized environment  
âœ… **Scalable Architecture** â€” modular and production-ready code design  

---

## ğŸ§© Tech Stack

| Component | Tool |
|------------|------|
| **Language** | Python ğŸ |
| **Version Control** | Git & GitHub |
| **Data Versioning** | DVC |
| **Experiment Tracking** | MLflow |
| **Remote Tracking & Visualization** | DagsHub |
| **Containerization** | Docker |
| **Logging** | Custom Python Logging |

---

## ğŸ“ Project Structure

```plaintext
.
â”œâ”€â”€ .dvc/                 # DVC metadata for data and model tracking
â”œâ”€â”€ artifact/             # Stored artifacts such as trained models
â”œâ”€â”€ catboost_info/        # Model training logs (CatBoost)
â”œâ”€â”€ logs/                 # Custom logs for training and evaluation
â”œâ”€â”€ notebook/             # Jupyter notebooks for experiments
â”œâ”€â”€ src/mlproj/           # Core project source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ utils.py
â”‚   â”œâ”€â”€ data_loader.py
â”‚   â”œâ”€â”€ model_trainer.py
â”‚   â”œâ”€â”€ evaluation.py
â”‚   â””â”€â”€ pipeline.py
â”œâ”€â”€ .dvcignore            # Files ignored by DVC
â”œâ”€â”€ .gitignore            # Files ignored by Git
â”œâ”€â”€ Dockerfile            # Containerization setup
â”œâ”€â”€ README.md             # Project documentation
â”œâ”€â”€ app.py                # Main application entry point
â”œâ”€â”€ requirements.txt      # Project dependencies
â”œâ”€â”€ setup.py              # Setup configuration for packaging
â””â”€â”€ template.py           # Initial project template

```
---
# ğŸ§° Installation & Setup

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/rhythmchauhann/MLPROJ.git
cd MLPROJ
```

### 2ï¸âƒ£ Create and activate a virtual environment
```bash
python -m venv venv
venv\Scripts\activate      # On Windows
source venv/bin/activate   # On Mac/Linux
```

### 3ï¸âƒ£ Install dependencies
```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Initialize DVC
```bash
dvc init
dvc pull  # Download remote dataset if available
```

### 5ï¸âƒ£ Run the main application
```bash
python app.py
```

---

## ğŸ“Š MLflow + DagsHub Tracking

Each model training run automatically logs:
- Parameters
- Metrics
- Model artifacts
- Run timestamps

All experiments can be visualized on your **DagsHub dashboard**:

ğŸ”— [View MLflow Runs on DagsHub](https://dagshub.com/rhythmchauhann/MLPROJ)

---



### ğŸ” Workflow Explanation
- **Data Loading** â€” Reads and validates the dataset.  
- **Preprocessing** â€” Handles cleaning, encoding, and transformations.  
- **Training** â€” Trains multiple ML models (Linear Regression, CatBoost, RandomForest, etc.).  
- **Evaluation** â€” Compares metrics and selects the top-performing model.  
- **Tracking** â€” Logs results and parameters with MLflow.  
- **Versioning** â€” Saves datasets and models with DVC for reproducibility.  

---

## ğŸ§± Docker Support

Run the entire project inside a Docker container for full reproducibility.

### ğŸ³ Build the Docker image
```bash
docker build -t mlproj .
```

### â–¶ï¸ Run the container
```bash
docker run -it mlproj
```

---

## ğŸ“ˆ Results

âœ… Automatic multi-model evaluation  
âœ… Best model saved and logged  
âœ… Fully tracked experiments in MLflow  
âœ… Versioned data and models with DVC  
âœ… Dashboard integration via DagsHub  

---

## ğŸ’¡ Future Improvements

- ğŸ” Add automated CI/CD with GitHub Actions  
- â˜ï¸ Integrate cloud storage (AWS S3 / GCP)  
- ğŸŒ Deploy REST API endpoints for inference  
- ğŸ“Š Add model monitoring and retraining pipeline  

---

## ğŸ§‘â€ğŸ’» Author

**Rhythm Chauhann**  
ğŸ“ AI/ML Engineer | Data Science 

ğŸ“ **Connect:**  
- [GitHub](https://github.com/rhythmchauhann)  
- [DagsHub Project](https://dagshub.com/rhythmchauhann/MLPROJ)  

---

â­ *If you like this project, don't forget to give it a star!* â­
